%
% File naacl2019.tex
%
%% Based on the style files for ACL 2018 and NAACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}

\newcommand{\ahcomment}[1]{\textcolor{blue}{[#1 -AH]}}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Extractive sentence compression under lexical and length constraints}

\author{First Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\\And
  Second Author \\
  Affiliation / Address line 1 \\
  Affiliation / Address line 2 \\
  Affiliation / Address line 3 \\
  {\tt email@domain} \\}

\date{}

\begin{document}
\maketitle

\begin{abstract}
TODO
\end{abstract}

\section{Outline}

\begin{enumerate}
\item{$(q,s,r)$ compression is useful.}
\item{How do you do it? ILPs, neural net taggers, iterative deletion supervised w/ people or w/ gold data? (\S\ref{s:method}).}
\item{Why iterative deletion is good. Description of current system for making deletion decisions w/ human supervision. Possibly make this system better too}
\item{Computational experiments (1): Properties of q,s,r compression in English. }
\item{Computational experiments (2): F and A data, interpreted as q,s,r supervision/data. Enumerate methods and bold the one with the best token-level F1 score.}
\item{Possible post hoc human experiment? Is our system actually good?}
\end{enumerate}




\section{Why iterative deletion is good}\label{s:method}
\begin{enumerate}
\item{Historical reasons}
\item{grammatical bias + syntax bias + linguistically-motivated? Leverages a lot that is know from linguistics: e.g. adjuncts, transitive bias, function words.}
\item{budget and query are trivial}
\item{linear (taggers) vs. quadratic (this work) vs. ILPs (exponential). }
\item{single op supervision can be used}
\item{avoid computational waste w/ grammar! HUGE divergence between mathematical properties of compression problem (exponential) and ways you can actually compress a sentence.}
\item{One thought: you could do a neural system that decides when/what to delete, using F and A as supervision? Each tree gets an encoding and you do a pointer network style softmax over trees? This sounds hard to implement.}
\end{enumerate}

\subsection{Preprocessing with extract}
Extract preprocessing. Make up a few simple rules. They will help a bunch. Only like 6 dependency types work at all for extract. This is in realfake/createdata/extract at the moment.

\section{Computational experiments part 1: investigating properties of q,s,r compression}
\begin{enumerate}
\item{q = a list of 1 to 3 NER}
\item{r = random}
\item{What is the size of the minimum compression?}
\item{Reachability by budget by position of q in syntax tree. (If q is more than one entity then how the entities are dispersed across the tree probably matters a bunch too).}
\item{Hang on. reachability == min compression, eh? if min compression $>$ b, it is clearly bad.}
\item{Avoid computational waste w/ grammar.  Examine: ops you never have to worry about if you prune a branch v. dependency type deletion endorsement rate. Some ops get rid of lots of tokens w/ very high probability of deletion endorsements: e.g. parataxis (a great op!). By contrast: pruning a noun subj destroys acceptability and usually does not delete many tokens. Not worth the risk!}
\item{What is the empirical number of ops (i.e. decisions you have to make about pruning) if you greedily drop branches but never drop if the single op probability is less than $p$? My guess is you can make this problem way, way, simpler than implied by exponential formulation. Is it really quadratic?}
\item{Distribution of number of ops used for different q and r: when choosing ops at random? when choosing greedily? When pruning $\propto$ p(endorsement)?}
\item{Other stuff: min compression, reachability, operations saved w/ big prunes? position of query in the tree?}
\end{enumerate}

\section{Computational experiments part 2: sentence compression}
Interpret F and A as Q,S,R supervision/data. Then test methods which do $(q,s,r)$ compression. Measure w/ token level F1.


\begin{table}[htb!]
\begin{tabular}{ll}
\centering
Approach & F1 \\ \hline
Human acceptability supervision         &  A          \\
F and A (2013)    & B           \\
C and L (2008)    & C        \\
Neural subtree deletion methods? &  D    \\   
\end{tabular}
\end{table}

\begin{enumerate}
\item{q = a list of 1 to 3 NER which are in the compression. All the NER in the compression? If the compression has no NER, use noun unigrams I guess? or probably just skip it}
\item{r = length of gold}
\end{enumerate}

\ahcomment{what do they do in IR for query biased snippets? Hamed, John, Jieppu.
 (Prior study suggests that grammatical malformations cause readability errors in search results \cite{kanungo2009predicting}).}

\section{TODO}
\begin{enumerate}
\item{How will we deal with semantics? Brendan email about subsective adjectives ellie pavlik work. }
\end{enumerate}

\section{Related work}

Traditional study of sentence compression is closely aligned with text summarization techniques that select and  shorten sentences \cite{Knight2000StatisticsBasedS,vanderwende2007beyond,clarke2008global,Nenkova2012ASO}. 
In these settings, it is important for compressions to retain ``important'' information from source sentences because they must stand-in for longer sentences within summaries.

Our concern with lexical constraints is better suited to applications in which user queries define important information in documents. For instance, our length and lexically-constrained compressions could be used in information retrieval systems that summarize search results using query-based snippets on a search engine results page \cite{tombros1998advantages,Metzler2008MachineLS}. Often, such snippets must contain query terms. \ahcomment{screenshot?}

Our method could also be used for particular forms of query-focused summarization, such as summarizing people \cite{w04} or companies \cite{filippova2009company} which might require a hard lexical constraint. (Other work on query-focused summarization \cite{das} assumes softer constraints). 

Length and lexically constrained compressions could also be used as part of new forms of search user interfaces \cite{hearst2009search}, such as concept map browsers \cite{falke2017graphdocexplore}. Our interest in this problem arose from constructing one such novel search system.

\bibliography{abe}
\bibliographystyle{acl_natbib}

\end{document}
