{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from code.printers import pretty_print_conl\n",
    "from sklearn.metrics import f1_score\n",
    "from __future__ import division\n",
    "from code.treeops import bfs\n",
    "dev = [json.loads(_) for _ in open(\"dev.jsonl\")]\n",
    "train = [json.loads(_) for _ in open(\"mini.train.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6611305836257646"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def heuristic_extract(jdoc):\n",
    "    '''\n",
    "    return the lowest vertex in the tree that contains the query terms\n",
    "    '''\n",
    "    from_root = [_['dependent'] for _ in jdoc[\"basicDependencies\"] if _['governor'] == 0][0]\n",
    "    best = from_root\n",
    "    def tok_is_verb(vertex):\n",
    "        gov = [o[\"pos\"][0] for o in jdoc[\"tokens\"] if o[\"index\"] == v][0]\n",
    "        return gov[0].lower() == \"v\"\n",
    "    for v in get_walk_from_root(jdoc):  # bfs\n",
    "        children = dfs(g=jdoc, hop_s=v, D=[])\n",
    "        # the verb heuristic is b/c the min governing tree is often just Q itself\n",
    "        if all(i in children for i in jdoc[\"q\"]) and tok_is_verb(v):\n",
    "            best = v\n",
    "    return best\n",
    "\n",
    "def get_path_to_root(v, jdoc):\n",
    "    def get_parent(v):\n",
    "        for _ in jdoc[\"basicDependencies\"]:\n",
    "            if _[\"dependent\"] == v:\n",
    "                return _[\"governor\"]\n",
    "        return _[\"governor\"]\n",
    "    out = [v]\n",
    "    parent = get_parent(v)\n",
    "    while parent != 0:\n",
    "        v = parent\n",
    "        out.append(parent)\n",
    "        parent = get_parent(v)\n",
    "    return out\n",
    "\n",
    "def min_tree_to_root(jdoc):\n",
    "    return {i for q in jdoc[\"q\"] for i in get_path_to_root(q, jdoc)}\n",
    "\n",
    "def len_tree(tree, jdoc):\n",
    "    return sum(len(o['word']) for o in jdoc[\"tokens\"] if o[\"index\"] in tree)\n",
    "\n",
    "\n",
    "def get_options(tree, jdoc):\n",
    "    optionsd = {o[\"dependent\"] for o in jdoc[\"basicDependencies\"] if o[\"governor\"] in tree and o[\"dependent\"] not in tree}\n",
    "    optionsg = {o[\"governor\"] for o in jdoc[\"basicDependencies\"] if o[\"dependent\"] in tree and o[\"governor\"] not in tree}\n",
    "    return optionsd | optionsg\n",
    "    \n",
    "def append_at_random(tree, jdoc):\n",
    "    s = get_options(tree, jdoc)\n",
    "    added = random.sample(s, 1)[0]\n",
    "    assert added not in tree\n",
    "    tree.add(added)\n",
    "\n",
    "def bottom_up_compression_random(jdoc):\n",
    "    tree = min_tree_to_root(jdoc=jdoc)\n",
    "    while len_tree(tree=tree, jdoc=jdoc) < jdoc[\"r\"]:\n",
    "        try:\n",
    "            append_at_random(tree, jdoc)\n",
    "        except ValueError: # it is possible to back into a corner where there are no V left to add.\n",
    "                           # in these cases, you cant make compression longer and should just stop\n",
    "            return tree\n",
    "    return tree\n",
    "\n",
    "def print_gold(jdoc):\n",
    "    gold = jdoc[\"compression_indexes\"]\n",
    "    print \" \".join([_[\"word\"] for _ in jdoc[\"tokens\"] if _[\"index\"] in gold])\n",
    "\n",
    "def print_tree(tree, jdoc):\n",
    "    tk = [_[\"word\"] for _ in jdoc[\"tokens\"] if _[\"index\"] in tree]\n",
    "    print \" \".join(tk)\n",
    "    \n",
    "def get_f1(predicted, jdoc):\n",
    "    original_ixs = [_[\"index\"] for _ in jdoc[\"tokens\"]]\n",
    "    y_true = [_ in jdoc['compression_indexes'] for _ in original_ixs]\n",
    "    y_pred = [_ in predicted for _ in original_ixs]\n",
    "    return f1_score(y_true=y_true, y_pred=y_pred)\n",
    "\n",
    "def f1_experiment(sentence_set, f=bottom_up_compression_random):\n",
    "    tot = 0\n",
    "    for sentence in sentence_set:\n",
    "        predicted = f(sentence)\n",
    "        tot += get_f1(predicted, sentence)\n",
    "    return tot/len(lns)\n",
    "\n",
    "f1_experiment(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cc': 0.0299625468164794, u'nmod:tmod': 0.02247191011235955, u'compound:prt': 0.003745318352059925, u'nsubjpass': 0.011235955056179775, u'conj': 0.0299625468164794, u'dobj': 0.04119850187265917, u'neg': 0.00749063670411985, u'mark': 0.003745318352059925, u'auxpass': 0.00749063670411985, u'advcl': 0.018726591760299626, u'aux': 0.03745318352059925, u'parataxis': 0.0149812734082397, u'xcomp': 0.0299625468164794, u'nsubj': 0.09363295880149813, u'nummod': 0.00749063670411985, u'advmod': 0.018726591760299626, u'punct': 0.27340823970037453, u'compound': 0.06741573033707865, u'ccomp': 0.018726591760299626, u'nmod:poss': 0.0149812734082397, u'case': 0.018726591760299626, u'cop': 0.011235955056179775, u'dep': 0.018726591760299626, u'appos': 0.00749063670411985, u'det': 0.0299625468164794, u'nmod': 0.08239700374531835, u'amod': 0.0299625468164794, u'acl:relcl': 0.02247191011235955, u'root': 0.003745318352059925, u'acl': 0.02247191011235955}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "dep_counter = defaultdict(list)\n",
    "\n",
    "for _ in train:\n",
    "    toks = [i for i in _[\"tokens\"] if i[\"index\"] in _[\"compression_indexes\"] + [0]]\n",
    "    for t in toks:\n",
    "        gov = [d[\"dep\"] for d in _[\"basicDependencies\"] if d[\"dependent\"] == t[\"index\"]]\n",
    "        assert len(gov) == 1\n",
    "        gov = gov[0]\n",
    "        dep = [d[\"dep\"] for d in _[\"basicDependencies\"] if d[\"governor\"] == t[\"index\"]]\n",
    "        for d in dep:\n",
    "            dep_counter[gov].append(d)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "dep_probs = defaultdict()\n",
    "for d in dep_counter:\n",
    "    c = Counter(dep_counter[d])\n",
    "    c = {k:v/sum(c.values()) for k,v in c.items()}\n",
    "    dep_probs[d] = c\n",
    "    \n",
    "print dep_probs['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n",
      "[*] Index error\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72037993691311897"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_children_to_q(vx, q, sentence, tree):\n",
    "    '''add a vertexes children to a queue, sort by prob'''\n",
    "    children = [d for d in sentence['basicDependencies'] if d[\"governor\"] == vx if d[\"dep\"] not in [\"punct\"]]\n",
    "    governor = [d for d in sentence['basicDependencies'] if d[\"dependent\"] == vx][0]\n",
    "    for c in children:\n",
    "        try:\n",
    "            c[\"prob\"] = dep_probs[governor[\"dep\"]][c[\"dep\"]]\n",
    "        except KeyError:\n",
    "            c[\"prob\"] = 0\n",
    "        if c[\"dependent\"] not in tree:\n",
    "            q.append(c)\n",
    "    q.sort(key=lambda x:x[\"prob\"], reverse=True)\n",
    "\n",
    "def remove_from_q(vx, Q, sentence):\n",
    "    '''add a vertexes children to a queue, sort by prob'''\n",
    "    for ino, i in enumerate(Q):\n",
    "        if i[\"dependent\"] == vx:\n",
    "            del Q[ino]\n",
    "            break\n",
    "\n",
    "def bottom_up_from_corpus(sentence):            \n",
    "    tree = min_tree_to_root(jdoc=sentence)\n",
    "    q_by_prob = []\n",
    "    for item in tree:\n",
    "        add_children_to_q(item, q_by_prob, sentence, tree)\n",
    "\n",
    "\n",
    "    while len_tree(tree, sentence) < sentence[\"r\"]:\n",
    "        try:\n",
    "            new_vx = q_by_prob[0][\"dependent\"]\n",
    "            tree.add(new_vx)\n",
    "            add_children_to_q(new_vx, q_by_prob, sentence, tree)\n",
    "            remove_from_q(new_vx, q_by_prob, sentence)\n",
    "        except IndexError:\n",
    "            print \"[*] Index error\" # these are mostly parse errors from punct governing parts of the tree.\n",
    "            return tree \n",
    "    \n",
    "    return tree\n",
    "\n",
    "f1_experiment(dev,f=bottom_up_from_corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
